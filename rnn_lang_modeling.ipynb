{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><b>Рекуррентная нейронная сеть и </b> <span style=\"font-weight:bold; color:green\">TensorFlow</span></div><hr>\n",
    "<div style=\"text-align:right;\">Папулин С.Ю. <span style=\"font-style: italic;font-weight: bold;\">(papulin_hse@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Подключение стилей оформления</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<link href=\"css/style.css\" rel=\"stylesheet\" type=\"text/css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import rnn_lang_modeling_reader as reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">1. Загрузка исходных данных</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Вариант 1.</b> Из командной строки</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P data/rnn-lang-modeling/ http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xvf data/rnn-lang-modeling/simple-examples.tgz -C data/rnn-lang-modeling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Вариант 2.</b> Средствами Python</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import shutil\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\"\n",
    "\n",
    "filename = \"data/rnn-lang-modeling/rnn-simple.tgz\"\n",
    "\n",
    "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "# Загрузка архива\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    with open(filename, 'wb') as output:\n",
    "        shutil.copyfileobj(response, output)\n",
    "\n",
    "# Распаковка\n",
    "with tarfile.open(filename) as tar:\n",
    "    tar.extractall(path=\"data/rnn-lang-modeling/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Директория с исходными данными и для записи логов и модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/rnn-lang-modeling/simple-examples/data\"\n",
    "save_path = \"log/rnn-lang-modeling/log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных и преобразование в вектор индексов слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, vocabulary = reader.ptb_raw_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество слов (токенов) в обучающем подмножестве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индекс первого слова в тестовом подмножестве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словарь преобразования слов в индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратное пребразование индекса первого слова тестового подмножества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in vocabulary:\n",
    "    if vocabulary[key] == test_data[0]:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">2. Этапы построения сети</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Параметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 24 # количество развертки LSTM\n",
    "hidden_size = 200 # количество LSTM единиц\n",
    "vocab_size = 10000 # размер словаря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры инициализации весов и параметры обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.0 # коэффициент скорости обучения\n",
    "max_grad_norm = 5 # предельно допустимая норма градиента\n",
    "max_epoch = 4 # количество обученных эпох с изначальным коэффициентом скорости обучения \n",
    "max_max_epoch = 13 # количество эпох\n",
    "lr_decay = 0.5 # затухание скорости обучения для каждой эпохи после «max_epoch»\n",
    "batch_size = 20 # размер batch\n",
    "batch_size_test = 1 # размер batch при тестировании\n",
    "num_steps_test = 1 # количество развертки LSTM при тестировании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size_train = ((len(train_data) // batch_size) - 1) // num_steps # размер эпохи\n",
    "epoch_size_valid = ((len(valid_data) // batch_size) - 1) // num_steps\n",
    "epoch_size_test = ((len(test_data) // batch_size_test) - 1) // num_steps_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Формирование исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = reader.ptb_producer(train_data, batch_size, num_steps, name=\"TrainInput\")\n",
    "x_valid, y_valid = reader.ptb_producer(valid_data, batch_size, num_steps, name=\"ValidInput\")\n",
    "x_test, y_test = reader.ptb_producer(test_data, batch_size_test, num_steps_test, name=\"TestInput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Построение сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование слов в распределенное представление (word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = tf.get_variable(\"embedding\", [vocab_size, hidden_size], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = tf.nn.embedding_lookup(embedding, x_train)\n",
    "inputs_valid = tf.nn.embedding_lookup(embedding, x_valid)\n",
    "inputs_test = tf.nn.embedding_lookup(embedding, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание двух слоев LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer_1 = tf.nn.rnn_cell.LSTMCell(hidden_size, forget_bias=0.0, \n",
    "                                            state_is_tuple=True,\n",
    "                                            reuse=tf.get_variable_scope().reuse)\n",
    "lstm_layer_2 = tf.nn.rnn_cell.LSTMCell(hidden_size, forget_bias=0.0, \n",
    "                                            state_is_tuple=True, \n",
    "                                            reuse=tf.get_variable_scope().reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Сотовая диаграмма LSTM</b>\n",
    "\n",
    "<img src=\"images/rnn-lang-modeling/lstm_cell.png\" width=\"670px\">\n",
    "\n",
    "<b>x<sub>t</sub></b> - входной вектор (слово/последовательность)\n",
    "\n",
    "<b>h<sub>t-1</sub></b> - результат предыдущей соты h<sub>t-1</sub>\n",
    "\n",
    "<b>s<sub>t</sub></b> - внутренняя переменная состояния t\n",
    "\n",
    "<b>s<sub>t-1</sub></b> - внутренняя переменная состояния t-1 (создание эффекта повторения -> снижение вероятности исчезновения градиента)\n",
    "\n",
    "<b>h<sub>t</sub></b> - выходной вектор\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение слоев в одну структуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_cell = tf.nn.rnn_cell.MultiRNNCell([lstm_layer_1, lstm_layer_2], state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Развернутая рекуррентная нейронная сеть</b>\n",
    "\n",
    "<img src=\"images/rnn-lang-modeling/rnn.png\" width=\"696px\">\n",
    "\n",
    "На каждом временном шаге развертки LSTM подбирается новое слово, вывод h<sub>t-1</sub> предыдущей F соты подается в новую соту для определения следующего слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация начальных значений состояний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state_train = multiple_cell.zero_state(batch_size, tf.float32)\n",
    "initial_state_valid = multiple_cell.zero_state(batch_size, tf.float32)\n",
    "initial_state_test = multiple_cell.zero_state(batch_size_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение начальных и выходных состояний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = tf.unstack(inputs_train, num=num_steps, axis=1)\n",
    "inputs_valid = tf.unstack(inputs_valid, num=num_steps, axis=1)\n",
    "inputs_test = tf.unstack(inputs_test, num=num_steps_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_train, state_train = tf.nn.static_rnn(multiple_cell, inputs_train, initial_state=initial_state_train)\n",
    "outputs_valid, state_valid = tf.nn.static_rnn(multiple_cell, inputs_valid, initial_state=initial_state_valid)\n",
    "outputs_test, state_test = tf.nn.static_rnn(multiple_cell, inputs_test, initial_state=initial_state_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_train[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>LSTM архитектура сети</b>\n",
    "\n",
    "<img src=\"images/rnn-lang-modeling/lstm_architecture.png\" width=\"541px\">\n",
    "\n",
    "Размерность входных текстовых данных упорядочена следующим образом: (размер batch, количество развертки LSTM, количество LSTM единиц). \n",
    "\n",
    "Так для каждого batch и каждого слова в развертке LSTM существует вектор слоя внедрения длиной 200 для представления входного слова. Входные данные подаются в два «сложенных» слоя слотов LSTM. Вывод из этих развернутых слотов остается неизменным (размер batch, количество развертки LSTM, количество LSTM единиц).\n",
    "\n",
    "Затем выходные данные передаются в полностью связанный слой Dense, на котором применяется функция активации softmax, возвращая массив вероятностных оценок. Оценки сравниваются с данными обучения y для каждой соты, затем выполняется обратное распространение ошибки и градиента. \n",
    "\n",
    "Так на каждом временном шаге модель пытается предсказать следующее следующее слово в последовательности.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисление вероятности появления данных из y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train = tf.reshape(tf.stack(axis=1, values=outputs_train), [-1, hidden_size])\n",
    "output_valid = tf.reshape(tf.stack(axis=1, values=outputs_valid), [-1, hidden_size])\n",
    "output_test = tf.reshape(tf.stack(axis=1, values=outputs_test), [-1, hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_w = tf.get_variable(\"softmax_w\", [hidden_size, vocab_size], dtype=tf.float32)\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [vocab_size], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование logits в трехмерный тензор для последовательности потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_train = tf.matmul(output_train, softmax_w) + softmax_b\n",
    "logits_valid = tf.matmul(output_valid, softmax_w) + softmax_b\n",
    "logits_test = tf.matmul(output_test, softmax_w) + softmax_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_sample = tf.multinomial(logits_test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции потерь усредненные по batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits_train],\n",
    "                                                          [tf.reshape(y_train, [-1])], \n",
    "                                                          [tf.ones([batch_size * num_steps],\n",
    "                                                                   dtype=tf.float32)])\n",
    "\n",
    "loss_valid = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits_valid],\n",
    "                                                          [tf.reshape(y_valid, [-1])], \n",
    "                                                          [tf.ones([batch_size * num_steps],\n",
    "                                                                   dtype=tf.float32)])\n",
    "\n",
    "loss_test = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits_test],\n",
    "                                                          [tf.reshape(y_test, [-1])], \n",
    "                                                          [tf.ones([batch_size_test * num_steps_test],\n",
    "                                                                   dtype=tf.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = tf.reduce_sum(loss_train) / batch_size\n",
    "loss_valid = tf.reduce_sum(loss_valid) / batch_size\n",
    "loss_test = tf.reduce_sum(loss_test) / batch_size_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечное состояние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state_train = state_train\n",
    "final_state_valid = state_valid\n",
    "final_state_test = state_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.Variable(0.0, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(loss_train, tvars), max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Назначение оптимизатора (выполняться будет на batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars),\n",
    "                                           global_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lr = tf.placeholder(tf.float32, shape=[], name=\"new_learning_rate\")\n",
    "lr_update = tf.assign(lr, new_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">3. Запуск обучения</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = tf.train.Supervisor(logdir=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(session, initial_state, loss, final_state, epoch_size, \n",
    "              num_steps, batch_size, eval_op=None, verbose=False):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    losses = 0.0\n",
    "    iters = 0\n",
    "    state = session.run(initial_state)\n",
    "\n",
    "    fetches = {\n",
    "      \"loss\": loss,\n",
    "      \"final_state\": final_state,\n",
    "    }\n",
    "    if eval_op is not None:\n",
    "        fetches[\"eval_op\"] = eval_op\n",
    "\n",
    "    for step in range(epoch_size):\n",
    "        \n",
    "        feed_dict = {}\n",
    "        \n",
    "        #состояние слота (state cell) и скртытое состояние (hidden state)\n",
    "        for i, (c, h) in enumerate(initial_state):\n",
    "            feed_dict[c] = state[i].c\n",
    "            feed_dict[h] = state[i].h \n",
    "        \n",
    "        vals = session.run(fetches, feed_dict)\n",
    "        loss = vals[\"loss\"]\n",
    "        state = vals[\"final_state\"]\n",
    "\n",
    "        losses += loss\n",
    "        iters += num_steps\n",
    "\n",
    "        if verbose and step % (epoch_size // 10) == 10:\n",
    "            print(\"%.3f perplexity: %.3f speed: %.0f wps\" %\n",
    "                (step * 1.0 / epoch_size, np.exp(losses / iters),\n",
    "                 iters * batch_size / (time.time() - start_time)))\n",
    "\n",
    "    return np.exp(losses / iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sv.managed_session() as session:\n",
    "    for i in range(max_max_epoch):\n",
    "        \n",
    "        # затухание скорости обучения для каждой эпохи после «max_epoch»\n",
    "        lr_decay = lr_decay ** max(i + 1 - max_epoch, 0.0)\n",
    "        \n",
    "        lr_value = learning_rate * lr_decay\n",
    "        session.run(lr_update, feed_dict={new_lr: lr_value})\n",
    "        \n",
    "        print(\"Epoch: %d Learning rate: %.3f\" % (i + 1, session.run(lr)))\n",
    "        \n",
    "        train_perplexity = run_epoch(session, initial_state_train, loss_train, final_state_train, epoch_size_train,\n",
    "                                     num_steps, batch_size, eval_op=train_op, verbose=True)\n",
    "        print(\"Train Perplexity: %.3f\" % train_perplexity)\n",
    "        \n",
    "        valid_perplexity = run_epoch(session, initial_state_valid, loss_valid, final_state_valid, epoch_size_valid,\n",
    "                                     num_steps, batch_size)\n",
    "        print(\"Valid Perplexity: %.3f\" % valid_perplexity + \"\\n\")\n",
    "\n",
    "    test_perplexity = run_epoch(session, initial_state_test, loss_test, final_state_test, epoch_size_test,\n",
    "                                     num_steps_test, batch_size_test)\n",
    "    print(\"Test Perplexity: %.3f\" % test_perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика <b>Perplexity</b> (растерянность) отражает распределение вероятностей предсказания объекта p и считается по следующей формуле:\n",
    "\n",
    "<img src=\"images/rnn-lang-modeling/perplexity.png\" width=\"231px\">\n",
    "\n",
    "В обработке естественного языка растерянность позволяет оценить языковые модели, подсчитывая обратную вероятность появления каждого последующего слова в сгенерированном тексте на основе распределения вероятностей обучающей выборки и выражается в двойке в положительной степени (чем ближе этот показатель к двум, тем точнее работает модель)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">4. Генерация текста</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование индексов в слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word = {}\n",
    "for c, i in vocabulary.items():\n",
    "    id_to_word[i] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Входная последовательность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = np.array(vocabulary['raising']).reshape(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для генерации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(session, initial_state, final_state, logits_sample, input_data, feed, text_length):\n",
    "    state = session.run(initial_state)\n",
    "    fetches = {\n",
    "        \"final_state\": final_state,\n",
    "        \"logits\": logits_sample\n",
    "    }\n",
    "    \n",
    "    generated_text = [feed]\n",
    "    \n",
    "    for i in range(text_length):\n",
    "        feed_dict = {}\n",
    "        feed_dict[input_data] = feed\n",
    "        \n",
    "        for i, (c, h) in enumerate(initial_state):\n",
    "            feed_dict[c] = state[i].c\n",
    "            feed_dict[h] = state[i].h\n",
    "        \n",
    "        vals = session.run(fetches, feed_dict)\n",
    "        \n",
    "\n",
    "        state = vals[\"final_state\"]\n",
    "        feed = vals[\"logits\"]\n",
    "        \n",
    "      \n",
    "        generated_text.append(feed)\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерированный текст на основе входной последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sv.managed_session() as session:\n",
    "    generated_text = generate_text(session, initial_state_test, final_state_test, logits_sample,\n",
    "                                   x_test, np.array(seed_text).reshape(1, 1), text_length)\n",
    "    generated_text = ' '.join([id_to_word[text[0, 0]] for text in generated_text])\n",
    "    \n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">5. Источники</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/models/tree/master/tutorials/rnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
